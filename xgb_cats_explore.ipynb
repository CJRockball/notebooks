{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3ea947d",
   "metadata": {},
   "source": [
    "# Explore Categorical Feature Encodings\n",
    "This notebook will compare a couple of different encodings for categorical features and compare ROC-AUC for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e7addf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load requirements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from category_encoders import TargetEncoder, WOEEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a334c066",
   "metadata": {},
   "source": [
    "Start by loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60e445fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>7</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>25</td>\n",
       "      <td>aug</td>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>514</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>18</td>\n",
       "      <td>jun</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>602</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>14</td>\n",
       "      <td>may</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>student</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>34</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>28</td>\n",
       "      <td>may</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>889</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>3</td>\n",
       "      <td>feb</td>\n",
       "      <td>902</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749995</th>\n",
       "      <td>29</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>1282</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>4</td>\n",
       "      <td>jul</td>\n",
       "      <td>1006</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749996</th>\n",
       "      <td>69</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>631</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>aug</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749997</th>\n",
       "      <td>50</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>217</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>apr</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749998</th>\n",
       "      <td>32</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-274</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>26</td>\n",
       "      <td>aug</td>\n",
       "      <td>108</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749999</th>\n",
       "      <td>42</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>1559</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>4</td>\n",
       "      <td>aug</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>failure</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750000 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age          job   marital  education default  balance housing loan  \\\n",
       "0        42   technician   married  secondary      no        7      no   no   \n",
       "1        38  blue-collar   married  secondary      no      514      no   no   \n",
       "2        36  blue-collar   married  secondary      no      602     yes   no   \n",
       "3        27      student    single  secondary      no       34     yes   no   \n",
       "4        26   technician   married  secondary      no      889     yes   no   \n",
       "...     ...          ...       ...        ...     ...      ...     ...  ...   \n",
       "749995   29     services    single  secondary      no     1282      no  yes   \n",
       "749996   69      retired  divorced   tertiary      no      631      no   no   \n",
       "749997   50  blue-collar   married  secondary      no      217     yes   no   \n",
       "749998   32   technician   married  secondary      no     -274      no   no   \n",
       "749999   42   technician   married  secondary      no     1559      no   no   \n",
       "\n",
       "         contact  day month  duration  campaign  pdays  previous poutcome  y  \n",
       "0       cellular   25   aug       117         3     -1         0  unknown  0  \n",
       "1        unknown   18   jun       185         1     -1         0  unknown  0  \n",
       "2        unknown   14   may       111         2     -1         0  unknown  0  \n",
       "3        unknown   28   may        10         2     -1         0  unknown  0  \n",
       "4       cellular    3   feb       902         1     -1         0  unknown  1  \n",
       "...          ...  ...   ...       ...       ...    ...       ...      ... ..  \n",
       "749995   unknown    4   jul      1006         2     -1         0  unknown  1  \n",
       "749996  cellular   19   aug        87         1     -1         0  unknown  0  \n",
       "749997  cellular   17   apr       113         1     -1         0  unknown  0  \n",
       "749998  cellular   26   aug       108         6     -1         0  unknown  0  \n",
       "749999  cellular    4   aug       143         1      1         7  failure  0  \n",
       "\n",
       "[750000 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df_train = pd.read_csv('data/raw/train.csv').drop(columns=['id'])\n",
    "df_test = pd.read_csv('data/raw/test.csv').drop(columns=['id'])\n",
    "\n",
    "display(df_train)\n",
    "\n",
    "target = ['y']\n",
    "cats = ['job','marital','education','default','housing','loan','contact','month','poutcome']\n",
    "nums = ['age', 'balance','day', 'duration', 'capaign','pdays']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d4eef",
   "metadata": {},
   "source": [
    "For an initial test of the dataset I use XGB. XGB is very forgiving and you can run almost any type of dataset. However, I like to impute nans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86bfe818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train.isnull().sum())\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6505f272",
   "metadata": {},
   "source": [
    "Let's create a dataframe to summarize the expeeriment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f3b5cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Coding Algo': [], 'Number of Features': [], 'Average Logloss': [], 'Average ROC-AUC': []}\n"
     ]
    }
   ],
   "source": [
    "cols = ['Coding Algo', 'Number of Features', 'Average Logloss', 'Average ROC-AUC']\n",
    "summary_dict = {k:[] for k in cols}\n",
    "print(summary_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4ad5d9",
   "metadata": {},
   "source": [
    "Let's start modeling with my favoprite, Label encoding. I start by replacing existing labels with number labels. For XGB we don't have to, it would take care of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24adb969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 17) (250000, 16)\n",
      "(750000, 17) (250000, 16)\n"
     ]
    }
   ],
   "source": [
    "def ord_trans(df, df1, cats):\n",
    "    train_len = len(df)\n",
    "    df_temp = pd.concat([df, df1], axis=0)\n",
    "    \n",
    "    for name in cats:\n",
    "        df_temp[name], _ = df_temp[name].factorize()\n",
    "        \n",
    "    df = df_temp.iloc[:train_len,:].copy()\n",
    "    df1 = df_temp.iloc[train_len:,:].copy()\n",
    "    df1 = df1.drop(columns=['y'])\n",
    "    return df, df1\n",
    "\n",
    "print(df_train.shape, df_test.shape)\n",
    "df_label_train, df_label_test = ord_trans(df_train, df_test, cats)\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55ee3ef",
   "metadata": {},
   "source": [
    "Use cross-validation make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9996fd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.26203\tvalidation_0-auc:0.93672\n",
      "[50]\tvalidation_0-logloss:0.15125\tvalidation_0-auc:0.96456\n",
      "[100]\tvalidation_0-logloss:0.14834\tvalidation_0-auc:0.96605\n",
      "[150]\tvalidation_0-logloss:0.14728\tvalidation_0-auc:0.96654\n",
      "[190]\tvalidation_0-logloss:0.14707\tvalidation_0-auc:0.96665\n",
      "Fold 1 Log Loss: 0.14707, AUC_ROC: 0.96665\n",
      "[0]\tvalidation_0-logloss:0.26362\tvalidation_0-auc:0.93599\n",
      "[50]\tvalidation_0-logloss:0.15177\tvalidation_0-auc:0.96481\n",
      "[100]\tvalidation_0-logloss:0.14893\tvalidation_0-auc:0.96621\n",
      "[150]\tvalidation_0-logloss:0.14784\tvalidation_0-auc:0.96673\n",
      "[164]\tvalidation_0-logloss:0.14765\tvalidation_0-auc:0.96680\n",
      "Fold 2 Log Loss: 0.14765, AUC_ROC: 0.96680\n",
      "[0]\tvalidation_0-logloss:0.26366\tvalidation_0-auc:0.93438\n",
      "[50]\tvalidation_0-logloss:0.15347\tvalidation_0-auc:0.96352\n",
      "[100]\tvalidation_0-logloss:0.15029\tvalidation_0-auc:0.96514\n",
      "[150]\tvalidation_0-logloss:0.14877\tvalidation_0-auc:0.96591\n",
      "[200]\tvalidation_0-logloss:0.14822\tvalidation_0-auc:0.96619\n",
      "[208]\tvalidation_0-logloss:0.14809\tvalidation_0-auc:0.96626\n",
      "Fold 3 Log Loss: 0.14809, AUC_ROC: 0.96626\n",
      "[0]\tvalidation_0-logloss:0.26214\tvalidation_0-auc:0.93459\n",
      "[50]\tvalidation_0-logloss:0.15057\tvalidation_0-auc:0.96483\n",
      "[100]\tvalidation_0-logloss:0.14781\tvalidation_0-auc:0.96621\n",
      "[150]\tvalidation_0-logloss:0.14694\tvalidation_0-auc:0.96668\n",
      "[169]\tvalidation_0-logloss:0.14651\tvalidation_0-auc:0.96687\n",
      "Fold 4 Log Loss: 0.14652, AUC_ROC: 0.96687\n",
      "[0]\tvalidation_0-logloss:0.26296\tvalidation_0-auc:0.93707\n",
      "[50]\tvalidation_0-logloss:0.15096\tvalidation_0-auc:0.96501\n",
      "[100]\tvalidation_0-logloss:0.14773\tvalidation_0-auc:0.96660\n",
      "[150]\tvalidation_0-logloss:0.14653\tvalidation_0-auc:0.96716\n",
      "[194]\tvalidation_0-logloss:0.14620\tvalidation_0-auc:0.96729\n",
      "Fold 5 Log Loss: 0.14620, AUC_ROC: 0.96729\n",
      "\n",
      "Overall Score, logloss: 0.14711, auc: 0.96677\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_y = df_label_train[['y']].copy()\n",
    "df_X = df_label_train.drop(columns=['y']).copy()\n",
    "Xtest = df_label_test.copy()\n",
    "\n",
    "KFOLD = 5\n",
    "kf = KFold(n_splits=KFOLD, shuffle=True, random_state=1337)\n",
    "\n",
    "fold_loglosses = []\n",
    "fold_metrics = []\n",
    "for i,(train_index, valid_index) in enumerate(kf.split(df_X)):\n",
    "    Xtrain = df_X.iloc[train_index]\n",
    "    ytrain = df_y.iloc[train_index]\n",
    "    Xvalid = df_X.iloc[valid_index]\n",
    "    yvalid = df_y.iloc[valid_index]\n",
    "    \n",
    "    # XGB    \n",
    "    # Early stopping call back, use to get best model back\n",
    "    es = xgb.callback.EarlyStopping(\n",
    "    rounds=50,\n",
    "    min_delta=1e-3,\n",
    "    save_best=True,\n",
    "    maximize=False,\n",
    "    data_name=\"validation_0\",\n",
    "    metric_name=\"logloss\",)\n",
    "    \n",
    "    model = XGBClassifier(tree_method='hist',\n",
    "                          n_estimators=2000, \n",
    "                          objective='binary:logistic',\n",
    "                          early_stopping_rounds=100, \n",
    "                          enable_categorical=True, \n",
    "                          eval_metric=['logloss', 'auc'],\n",
    "                          n_jobs=4,\n",
    "                          random_state=1337,\n",
    "                          callbacks=[es],\n",
    "                          \n",
    "                          max_depth = 6,)\n",
    "    \n",
    "    model = model.fit(Xtrain, ytrain, \n",
    "                      eval_set=[(Xvalid, yvalid)],\n",
    "                      verbose=50)\n",
    "    \n",
    "    # predict\n",
    "    ypred_proba = model.predict_proba(Xvalid)\n",
    "    ypred = model.predict(Xvalid)\n",
    "    fold_logloss = log_loss(yvalid, ypred_proba)\n",
    "    fold_metric = roc_auc_score(yvalid, ypred_proba[:,1])\n",
    "    \n",
    "    # save\n",
    "    fold_loglosses.append(fold_logloss)\n",
    "    fold_metrics.append(fold_metric)\n",
    "    print(f\"Fold {i+1} Log Loss: {fold_logloss:.5f}, AUC_ROC: {fold_metric:.5f}\")\n",
    "    \n",
    "\n",
    "print(f\"\\nOverall Score, logloss: {np.mean(fold_loglosses):.5f}, auc: {np.mean(fold_metrics):.5f}\")\n",
    "\n",
    "summary_list = ['Label', str(Xtrain.shape[1]), str(round(np.mean(fold_loglosses),5)), str(round(np.mean(fold_metrics),5))]\n",
    "for i, (k, v) in enumerate(summary_dict.items()):\n",
    "    v.append(summary_list[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc66b4f0",
   "metadata": {},
   "source": [
    "Try one-hot-encoding. get_dummies returns bool type which will be run as categorical in xgboos models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a55af85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of new cols:  26\n",
      "number of current cols:  (750000, 17)\n",
      "total new columns:  (750000, 43)\n",
      "should be 17 + 26 =  43\n",
      "new cols in test:  (250000, 42)\n",
      "should be:  42\n"
     ]
    }
   ],
   "source": [
    "new_cols = 0\n",
    "for name in cats:\n",
    "    new_cols += np.max(df_train[name].nunique() - 2,0)\n",
    "print('number of new cols: ', new_cols)\n",
    "\n",
    "print('number of current cols: ', df_train.shape)\n",
    "\n",
    "df_ohe_train = pd.get_dummies(df_train, prefix=cats, dummy_na=False, \n",
    "                           columns=cats, drop_first=True)\n",
    "df_ohe_test = pd.get_dummies(df_test, prefix=cats, columns=cats, drop_first=True)\n",
    "\n",
    "print('total new columns: ', df_ohe_train.shape)\n",
    "print('should be 17 + 26 = ', 17+26)\n",
    "print('new cols in test: ', df_ohe_test.shape)\n",
    "print('should be: ', df_test.shape[1] + 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fbd7e2",
   "metadata": {},
   "source": [
    "let make the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "926a0274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.26281\tvalidation_0-auc:0.93563\n",
      "[50]\tvalidation_0-logloss:0.15150\tvalidation_0-auc:0.96445\n",
      "[100]\tvalidation_0-logloss:0.14893\tvalidation_0-auc:0.96570\n",
      "[150]\tvalidation_0-logloss:0.14796\tvalidation_0-auc:0.96622\n",
      "[177]\tvalidation_0-logloss:0.14760\tvalidation_0-auc:0.96639\n",
      "Fold 1 Log Loss: 0.14759, AUC_ROC: 0.96640\n",
      "[0]\tvalidation_0-logloss:0.26467\tvalidation_0-auc:0.93516\n",
      "[50]\tvalidation_0-logloss:0.15322\tvalidation_0-auc:0.96408\n",
      "[100]\tvalidation_0-logloss:0.15011\tvalidation_0-auc:0.96559\n",
      "[150]\tvalidation_0-logloss:0.14844\tvalidation_0-auc:0.96646\n",
      "[175]\tvalidation_0-logloss:0.14831\tvalidation_0-auc:0.96655\n",
      "Fold 2 Log Loss: 0.14828, AUC_ROC: 0.96656\n",
      "[0]\tvalidation_0-logloss:0.26427\tvalidation_0-auc:0.93490\n",
      "[50]\tvalidation_0-logloss:0.15416\tvalidation_0-auc:0.96303\n",
      "[100]\tvalidation_0-logloss:0.15053\tvalidation_0-auc:0.96495\n",
      "[150]\tvalidation_0-logloss:0.14922\tvalidation_0-auc:0.96562\n",
      "[174]\tvalidation_0-logloss:0.14885\tvalidation_0-auc:0.96582\n",
      "Fold 3 Log Loss: 0.14885, AUC_ROC: 0.96582\n",
      "[0]\tvalidation_0-logloss:0.26329\tvalidation_0-auc:0.93216\n",
      "[50]\tvalidation_0-logloss:0.15220\tvalidation_0-auc:0.96402\n",
      "[100]\tvalidation_0-logloss:0.14860\tvalidation_0-auc:0.96583\n",
      "[150]\tvalidation_0-logloss:0.14738\tvalidation_0-auc:0.96640\n",
      "[193]\tvalidation_0-logloss:0.14703\tvalidation_0-auc:0.96659\n",
      "Fold 4 Log Loss: 0.14702, AUC_ROC: 0.96660\n",
      "[0]\tvalidation_0-logloss:0.26427\tvalidation_0-auc:0.93685\n",
      "[50]\tvalidation_0-logloss:0.15173\tvalidation_0-auc:0.96463\n",
      "[100]\tvalidation_0-logloss:0.14864\tvalidation_0-auc:0.96613\n",
      "[150]\tvalidation_0-logloss:0.14739\tvalidation_0-auc:0.96672\n",
      "[174]\tvalidation_0-logloss:0.14700\tvalidation_0-auc:0.96692\n",
      "Fold 5 Log Loss: 0.14699, AUC_ROC: 0.96692\n",
      "\n",
      "Overall Score, logloss: 0.14774, auc: 0.96646\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_y = df_ohe_train[['y']].copy()\n",
    "df_X = df_ohe_train.drop(columns=['y']).copy()\n",
    "Xtest = df_ohe_test.copy()\n",
    "\n",
    "KFOLD = 5\n",
    "kf = KFold(n_splits=KFOLD, shuffle=True, random_state=1337)\n",
    "\n",
    "fold_loglosses = []\n",
    "fold_metrics = []\n",
    "for i,(train_index, valid_index) in enumerate(kf.split(df_X)):\n",
    "    Xtrain = df_X.iloc[train_index]\n",
    "    ytrain = df_y.iloc[train_index]\n",
    "    Xvalid = df_X.iloc[valid_index]\n",
    "    yvalid = df_y.iloc[valid_index]\n",
    "    \n",
    "    # XGB    \n",
    "    # Early stopping call back, use to get best model back\n",
    "    es = xgb.callback.EarlyStopping(\n",
    "    rounds=50,\n",
    "    min_delta=1e-3,\n",
    "    save_best=True,\n",
    "    maximize=False,\n",
    "    data_name=\"validation_0\",\n",
    "    metric_name=\"logloss\",)\n",
    "    \n",
    "    model = XGBClassifier(tree_method='hist',\n",
    "                          n_estimators=2000, \n",
    "                          objective='binary:logistic',\n",
    "                          early_stopping_rounds=100, \n",
    "                          enable_categorical=True, \n",
    "                          eval_metric=['logloss', 'auc'],\n",
    "                          n_jobs=4,\n",
    "                          random_state=1337,\n",
    "                          callbacks=[es],\n",
    "                           \n",
    "                          max_depth = 6,)\n",
    "    \n",
    "    model = model.fit(Xtrain, ytrain, \n",
    "                      eval_set=[(Xvalid, yvalid)],\n",
    "                      verbose=50)\n",
    "    \n",
    "    # predict\n",
    "    ypred_proba = model.predict_proba(Xvalid)\n",
    "    ypred = model.predict(Xvalid)\n",
    "    fold_logloss = log_loss(yvalid, ypred_proba)\n",
    "    fold_metric = roc_auc_score(yvalid, ypred_proba[:,1])\n",
    "    \n",
    "    # save\n",
    "    fold_loglosses.append(fold_logloss)\n",
    "    fold_metrics.append(fold_metric)\n",
    "    print(f\"Fold {i+1} Log Loss: {fold_logloss:.5f}, AUC_ROC: {fold_metric:.5f}\")\n",
    "\n",
    "\n",
    "print(f\"\\nOverall Score, logloss: {np.mean(fold_loglosses):.5f}, auc: {np.mean(fold_metrics):.5f}\")\n",
    "summary_list = ['One Hot', str(Xtrain.shape[1]), str(round(np.mean(fold_loglosses),5)), str(round(np.mean(fold_metrics),5))]\n",
    "for i, (k, v) in enumerate(summary_dict.items()):\n",
    "    v.append(summary_list[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd85db4",
   "metadata": {},
   "source": [
    "Let's try target encoding. We need to do the target encoding inside the cv loop to avoid \n",
    "leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5efab26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.25916\tvalidation_0-auc:0.93935\n",
      "[50]\tvalidation_0-logloss:0.15113\tvalidation_0-auc:0.96468\n",
      "[100]\tvalidation_0-logloss:0.14841\tvalidation_0-auc:0.96604\n",
      "[150]\tvalidation_0-logloss:0.14698\tvalidation_0-auc:0.96674\n",
      "[175]\tvalidation_0-logloss:0.14666\tvalidation_0-auc:0.96691\n",
      "Fold 1 Log Loss: 0.14666, AUC_ROC: 0.96691\n",
      "[0]\tvalidation_0-logloss:0.26054\tvalidation_0-auc:0.93907\n",
      "[50]\tvalidation_0-logloss:0.15089\tvalidation_0-auc:0.96520\n",
      "[100]\tvalidation_0-logloss:0.14842\tvalidation_0-auc:0.96645\n",
      "[150]\tvalidation_0-logloss:0.14723\tvalidation_0-auc:0.96705\n",
      "[158]\tvalidation_0-logloss:0.14716\tvalidation_0-auc:0.96709\n",
      "Fold 2 Log Loss: 0.14716, AUC_ROC: 0.96709\n",
      "[0]\tvalidation_0-logloss:0.26036\tvalidation_0-auc:0.93847\n",
      "[50]\tvalidation_0-logloss:0.15241\tvalidation_0-auc:0.96405\n",
      "[100]\tvalidation_0-logloss:0.14968\tvalidation_0-auc:0.96540\n",
      "[150]\tvalidation_0-logloss:0.14844\tvalidation_0-auc:0.96601\n",
      "[181]\tvalidation_0-logloss:0.14808\tvalidation_0-auc:0.96620\n",
      "Fold 3 Log Loss: 0.14808, AUC_ROC: 0.96620\n",
      "[0]\tvalidation_0-logloss:0.25896\tvalidation_0-auc:0.93884\n",
      "[50]\tvalidation_0-logloss:0.15043\tvalidation_0-auc:0.96488\n",
      "[100]\tvalidation_0-logloss:0.14753\tvalidation_0-auc:0.96633\n",
      "[150]\tvalidation_0-logloss:0.14645\tvalidation_0-auc:0.96687\n",
      "[184]\tvalidation_0-logloss:0.14617\tvalidation_0-auc:0.96699\n",
      "Fold 4 Log Loss: 0.14617, AUC_ROC: 0.96699\n",
      "[0]\tvalidation_0-logloss:0.26013\tvalidation_0-auc:0.94045\n",
      "[50]\tvalidation_0-logloss:0.15055\tvalidation_0-auc:0.96521\n",
      "[100]\tvalidation_0-logloss:0.14794\tvalidation_0-auc:0.96646\n",
      "[150]\tvalidation_0-logloss:0.14679\tvalidation_0-auc:0.96699\n",
      "[169]\tvalidation_0-logloss:0.14675\tvalidation_0-auc:0.96703\n",
      "Fold 5 Log Loss: 0.14673, AUC_ROC: 0.96703\n",
      "\n",
      "Overall Score, logloss: 0.14696, auc: 0.96685\n"
     ]
    }
   ],
   "source": [
    "df_y = df_train[['y']].copy()\n",
    "df_X = df_train.drop(columns=['y']).copy()\n",
    "\n",
    "\n",
    "KFOLD = 5\n",
    "kf = KFold(n_splits=KFOLD, shuffle=True, random_state=1337)\n",
    "\n",
    "fold_loglosses = []\n",
    "fold_metrics = []\n",
    "for i,(train_index, valid_index) in enumerate(kf.split(df_X)):\n",
    "    Xtrain = df_X.iloc[train_index]\n",
    "    ytrain = df_y.iloc[train_index]\n",
    "    Xvalid = df_X.iloc[valid_index]\n",
    "    yvalid = df_y.iloc[valid_index]\n",
    "    Xtest = df_test.copy()\n",
    "    \n",
    "    enc = TargetEncoder(cols=cats, \n",
    "                    min_samples_leaf=20, \n",
    "                    smoothing=10).fit(Xtrain, ytrain)\n",
    "    Xtrain = enc.transform(Xtrain)\n",
    "    Xvalid = enc.transform(Xvalid)\n",
    "    Xtest = enc.transform(Xtest)\n",
    "\n",
    "    # XGB    \n",
    "    # Early stopping call back, use to get best model back\n",
    "    es = xgb.callback.EarlyStopping(\n",
    "    rounds=50,\n",
    "    min_delta=1e-3,\n",
    "    save_best=True,\n",
    "    maximize=False,\n",
    "    data_name=\"validation_0\",\n",
    "    metric_name=\"logloss\",)\n",
    "    \n",
    "    model = XGBClassifier(tree_method='hist',\n",
    "                          n_estimators=2000, \n",
    "                          objective='binary:logistic',\n",
    "                          early_stopping_rounds=100, \n",
    "                          enable_categorical=True, \n",
    "                          eval_metric=['logloss', 'auc'],\n",
    "                          n_jobs=4,\n",
    "                          random_state=1337,\n",
    "                          callbacks=[es],\n",
    "                           \n",
    "                          max_depth = 6,)\n",
    "    \n",
    "    model = model.fit(Xtrain, ytrain, \n",
    "                      eval_set=[(Xvalid, yvalid)],\n",
    "                      verbose=50)\n",
    "    \n",
    "    # predict\n",
    "    ypred_proba = model.predict_proba(Xvalid)\n",
    "    ypred = model.predict(Xvalid)\n",
    "    fold_logloss = log_loss(yvalid, ypred_proba)\n",
    "    fold_metric = roc_auc_score(yvalid, ypred_proba[:,1])\n",
    "    \n",
    "    # save\n",
    "    fold_loglosses.append(fold_logloss)\n",
    "    fold_metrics.append(fold_metric)\n",
    "    print(f\"Fold {i+1} Log Loss: {fold_logloss:.5f}, AUC_ROC: {fold_metric:.5f}\")\n",
    "    \n",
    "\n",
    "print(f\"\\nOverall Score, logloss: {np.mean(fold_loglosses):.5f}, auc: {np.mean(fold_metrics):.5f}\")\n",
    "summary_list = ['Target Encoding', str(Xtrain.shape[1]), str(round(np.mean(fold_loglosses),5)), str(round(np.mean(fold_metrics),5))]\n",
    "for i, (k, v) in enumerate(summary_dict.items()):\n",
    "    v.append(summary_list[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a8e9be",
   "metadata": {},
   "source": [
    "Let's try weight of evidence encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12693155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.25916\tvalidation_0-auc:0.93935\n",
      "[50]\tvalidation_0-logloss:0.15113\tvalidation_0-auc:0.96468\n",
      "[100]\tvalidation_0-logloss:0.14841\tvalidation_0-auc:0.96604\n",
      "[150]\tvalidation_0-logloss:0.14698\tvalidation_0-auc:0.96674\n",
      "[175]\tvalidation_0-logloss:0.14666\tvalidation_0-auc:0.96691\n",
      "Fold 1 Log Loss: 0.14666, AUC_ROC: 0.96691\n",
      "[0]\tvalidation_0-logloss:0.26054\tvalidation_0-auc:0.93907\n",
      "[50]\tvalidation_0-logloss:0.15089\tvalidation_0-auc:0.96520\n",
      "[100]\tvalidation_0-logloss:0.14842\tvalidation_0-auc:0.96645\n",
      "[150]\tvalidation_0-logloss:0.14723\tvalidation_0-auc:0.96705\n",
      "[158]\tvalidation_0-logloss:0.14716\tvalidation_0-auc:0.96709\n",
      "Fold 2 Log Loss: 0.14716, AUC_ROC: 0.96709\n",
      "[0]\tvalidation_0-logloss:0.26036\tvalidation_0-auc:0.93847\n",
      "[50]\tvalidation_0-logloss:0.15190\tvalidation_0-auc:0.96429\n",
      "[100]\tvalidation_0-logloss:0.14949\tvalidation_0-auc:0.96552\n",
      "[150]\tvalidation_0-logloss:0.14832\tvalidation_0-auc:0.96613\n",
      "[179]\tvalidation_0-logloss:0.14799\tvalidation_0-auc:0.96629\n",
      "Fold 3 Log Loss: 0.14799, AUC_ROC: 0.96629\n",
      "[0]\tvalidation_0-logloss:0.25896\tvalidation_0-auc:0.93884\n",
      "[50]\tvalidation_0-logloss:0.15043\tvalidation_0-auc:0.96488\n",
      "[100]\tvalidation_0-logloss:0.14753\tvalidation_0-auc:0.96633\n",
      "[150]\tvalidation_0-logloss:0.14645\tvalidation_0-auc:0.96687\n",
      "[184]\tvalidation_0-logloss:0.14617\tvalidation_0-auc:0.96699\n",
      "Fold 4 Log Loss: 0.14617, AUC_ROC: 0.96699\n",
      "[0]\tvalidation_0-logloss:0.26013\tvalidation_0-auc:0.94045\n",
      "[50]\tvalidation_0-logloss:0.15055\tvalidation_0-auc:0.96521\n",
      "[100]\tvalidation_0-logloss:0.14794\tvalidation_0-auc:0.96646\n",
      "[150]\tvalidation_0-logloss:0.14679\tvalidation_0-auc:0.96699\n",
      "[170]\tvalidation_0-logloss:0.14670\tvalidation_0-auc:0.96705\n",
      "Fold 5 Log Loss: 0.14670, AUC_ROC: 0.96705\n",
      "\n",
      "Overall Score, logloss: 0.14694, auc: 0.96687\n"
     ]
    }
   ],
   "source": [
    "df_y = df_train[['y']].copy()\n",
    "df_X = df_train.drop(columns=['y']).copy()\n",
    "Xtest = df_test.copy()\n",
    "\n",
    "KFOLD = 5\n",
    "kf = KFold(n_splits=KFOLD, shuffle=True, random_state=1337)\n",
    "\n",
    "fold_loglosses = []\n",
    "fold_metrics = []\n",
    "for i,(train_index, valid_index) in enumerate(kf.split(df_X)):\n",
    "    Xtrain = df_X.iloc[train_index]\n",
    "    ytrain = df_y.iloc[train_index]\n",
    "    Xvalid = df_X.iloc[valid_index]\n",
    "    yvalid = df_y.iloc[valid_index]\n",
    "    Xtest = df_test.copy()\n",
    "    \n",
    "    enc = WOEEncoder(cols=cats).fit(Xtrain, ytrain)\n",
    "    Xtrain = enc.transform(Xtrain)\n",
    "    Xvalid = enc.transform(Xvalid)\n",
    "    Xtest = enc.transform(Xtest)\n",
    "\n",
    "    # XGB    \n",
    "    # Early stopping call back, use to get best model back\n",
    "    es = xgb.callback.EarlyStopping(\n",
    "    rounds=50,\n",
    "    min_delta=1e-3,\n",
    "    save_best=True,\n",
    "    maximize=False,\n",
    "    data_name=\"validation_0\",\n",
    "    metric_name=\"logloss\",)\n",
    "    \n",
    "    model = XGBClassifier(tree_method='hist',\n",
    "                          n_estimators=2000, \n",
    "                          objective='binary:logistic',\n",
    "                          early_stopping_rounds=100, \n",
    "                          enable_categorical=True, \n",
    "                          eval_metric=['logloss', 'auc'],\n",
    "                          n_jobs=4,\n",
    "                          random_state=1337,\n",
    "                          callbacks=[es],\n",
    "                           \n",
    "                          max_depth = 6,)\n",
    "    \n",
    "    model = model.fit(Xtrain, ytrain, \n",
    "                      eval_set=[(Xvalid, yvalid)],\n",
    "                      verbose=50)\n",
    "    \n",
    "    # predict\n",
    "    ypred_proba = model.predict_proba(Xvalid)\n",
    "    ypred = model.predict(Xvalid)\n",
    "    fold_logloss = log_loss(yvalid, ypred_proba)\n",
    "    fold_metric = roc_auc_score(yvalid, ypred_proba[:,1])\n",
    "    \n",
    "    # save\n",
    "    fold_loglosses.append(fold_logloss)\n",
    "    fold_metrics.append(fold_metric)\n",
    "    print(f\"Fold {i+1} Log Loss: {fold_logloss:.5f}, AUC_ROC: {fold_metric:.5f}\")\n",
    "\n",
    "\n",
    "print(f\"\\nOverall Score, logloss: {np.mean(fold_loglosses):.5f}, auc: {np.mean(fold_metrics):.5f}\")\n",
    "summary_list = ['Weight of Evidence', str(Xtrain.shape[1]), str(round(np.mean(fold_loglosses),5)), str(round(np.mean(fold_metrics),5))]\n",
    "for i, (k, v) in enumerate(summary_dict.items()):\n",
    "    v.append(summary_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10542fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coding Algo</th>\n",
       "      <th>Number of Features</th>\n",
       "      <th>Average Logloss</th>\n",
       "      <th>Average ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Label</td>\n",
       "      <td>16</td>\n",
       "      <td>0.14711</td>\n",
       "      <td>0.96677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One Hot</td>\n",
       "      <td>42</td>\n",
       "      <td>0.14774</td>\n",
       "      <td>0.96646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Target Encoding</td>\n",
       "      <td>16</td>\n",
       "      <td>0.14696</td>\n",
       "      <td>0.96685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weight of Evidence</td>\n",
       "      <td>16</td>\n",
       "      <td>0.14694</td>\n",
       "      <td>0.96687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Coding Algo Number of Features Average Logloss Average ROC-AUC\n",
       "0               Label                 16         0.14711         0.96677\n",
       "1             One Hot                 42         0.14774         0.96646\n",
       "2     Target Encoding                 16         0.14696         0.96685\n",
       "3  Weight of Evidence                 16         0.14694         0.96687"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_summary = pd.DataFrame.from_dict(summary_dict)\n",
    "display(df_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
